{"id":"bcb46309-fa24-46ac-9785-487a746cb64e","name":"Microsoft GraphRAG Store","data":{"edges":[],"nodes":[{"data":{"type":"GraphRagStore","node":{"template":{"_type":"Component","embedding":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"name":"embedding","value":"","display_name":"Embedding","advanced":false,"input_types":["Embeddings"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"ingest_data":{"trace_as_metadata":true,"list":true,"trace_as_input":true,"required":true,"placeholder":"","show":true,"name":"ingest_data","value":"","display_name":"Ingest Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"DataInput"},"llm":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"name":"llm","value":"","display_name":"Language Model","advanced":false,"input_types":["LanguageModel"],"dynamic":false,"info":"","title_case":false,"type":"other","_input_type":"HandleInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import os\r\nimport shutil\r\nimport yaml\r\nfrom pathlib import Path\r\nimport subprocess\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DropdownInput, DataInput, Output, HandleInput, MessageTextInput\r\nfrom langflow.schema.message import Message\r\n\r\nfrom graphrag.index.cli import index_cli\r\nfrom graphrag.index.graph.extractors.claims.prompts import CLAIM_EXTRACTION_PROMPT\r\nfrom graphrag.index.graph.extractors.community_reports.prompts import COMMUNITY_REPORT_PROMPT\r\nfrom graphrag.index.graph.extractors.graph.prompts import GRAPH_EXTRACTION_PROMPT\r\nfrom graphrag.index.graph.extractors.summarize.prompts import SUMMARIZE_PROMPT\r\nfrom graphrag.index.init_content import INIT_DOTENV, INIT_YAML\r\nfrom graphrag.index.progress import ProgressReporter, NullProgressReporter\r\nfrom graphrag.index.progress.rich import RichProgressReporter\r\nfrom graphrag.config import StorageType\r\nimport graphrag.config.defaults as defs\r\n\r\nclass GraphRagStore(Component):\r\n    display_name = \"Microsoft GraphRAG Store\"\r\n    description = \"A component that uses GraphRag to index data.\"\r\n    STORAGE_TYPES = [StorageType.memory.value, StorageType.blob.value, StorageType.file.value]\r\n    ACCEPTED_LLM = [\"ollama-chat\", \"openai-chat\"]\r\n    \r\n    inputs = [\r\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\r\n        HandleInput(\r\n            name=\"embedding\",\r\n            display_name=\"Embedding\",\r\n            input_types=[\"Embeddings\"],\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"persist_directory\",\r\n            display_name=\"Persist Directory\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"storage_type\",\r\n            display_name=\"Storage Type\",\r\n            advanced=False,\r\n            options=STORAGE_TYPES,\r\n            value='file',\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"ingest_data\",\r\n            display_name=\"Ingest Data\",\r\n            required=True,\r\n            is_list=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"result_text\", method=\"save_data\")\r\n    ]\r\n    \r\n    def save_data(self) -> Message:\r\n        if not self.llm._llm_type or (self.llm._llm_type != \"ollama-chat\" and self.llm._llm_type != \"openai-chat\"):\r\n            raise ValueError(\"LLM must be Ollama or OpenAI model.\")\r\n        \r\n        if not self.embedding.model:\r\n            raise ValueError(\"Embedding must be Ollama or OpenAI embbedding.\")\r\n\r\n        is_saved = False\r\n        try:\r\n            progress_reporter = RichProgressReporter(\"GraphRAG Indexer \")\r\n            self.try_initialize_project_at(progress_reporter)\r\n            \r\n            self.set_settings()\r\n            if not os.path.exists('/link_volumes/graphrag/'):\r\n                print(\"Directory does not exist. Creating now.\")\r\n                os.makedirs('/link_volumes/graphrag/')\r\n            with open('/link_volumes/graphrag/test.txt', 'w') as f:\r\n                subprocess.call(['python', \"-m\", \"graphrag.index\", \"--root\", self.persist_directory], stdout=f)\r\n            \r\n            # index_cli(\r\n            #     root=self.persist_directory,\r\n            #     init=False,\r\n            #     verbose=False,\r\n            #     resume=None,\r\n            #     memprofile=True,\r\n            #     nocache=False,\r\n            #     reporter='none',\r\n            #     config=None,\r\n            #     emit=None,\r\n            #     dryrun=False,\r\n            #     cli=False,\r\n            # )\r\n            is_saved = True\r\n        except Exception as e:\r\n            is_saved = False\r\n            raise ValueError(f\"An error occurred: {str(e.with_traceback(None))}\")\r\n\r\n        if is_saved:\r\n            result = Message(text=\"Data saved successfully.\")\r\n        else:\r\n            result = Message(text=\"Data not saved.\")\r\n\r\n        self.status = result\r\n        return result\r\n\r\n    def try_initialize_project_at(self, reporter: ProgressReporter):\r\n        \"\"\"Initialize the project at the given path.\"\"\"\r\n        reporter.info(f\"Initializing project at {self.persist_directory}\")\r\n        root = Path(self.persist_directory)\r\n        if not root.exists():\r\n            root.mkdir(parents=True, exist_ok=True)\r\n\r\n        input_path = os.path.join(self.persist_directory, defs.INPUT_BASE_DIR)\r\n        if not os.path.exists(input_path):\r\n            os.makedirs(input_path)\r\n        for filename in os.listdir(input_path):\r\n            file_path = os.path.join(input_path, filename)\r\n            try:\r\n                if os.path.isfile(file_path) or os.path.islink(file_path):\r\n                    os.unlink(file_path)\r\n                elif os.path.isdir(file_path):\r\n                    shutil.rmtree(file_path)\r\n            except Exception as e:\r\n                print('Failed to delete %s. Reason: %s' % (file_path, e))\r\n        for i in range(len(self.ingest_data)):\r\n            f = open(os.path.join(input_path, f\"data{i}.txt\"), \"w\", encoding='utf-8')\r\n            f.write(self.ingest_data[i].get_text())\r\n            f.close()\r\n        \r\n        settings_yaml = root / \"settings.yaml\"\r\n        if settings_yaml.exists():\r\n            return\r\n\r\n        dotenv = root / \".env\"\r\n        if not dotenv.exists():\r\n            with settings_yaml.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(INIT_YAML)\r\n\r\n        with dotenv.open(\"w\", encoding=\"utf-8\") as file:\r\n            file.write(INIT_DOTENV)\r\n\r\n        prompts_dir = root / \"prompts\"\r\n        if not prompts_dir.exists():\r\n            prompts_dir.mkdir(parents=True, exist_ok=True)\r\n\r\n        entity_extraction = prompts_dir / \"entity_extraction.txt\"\r\n        if not entity_extraction.exists():\r\n            with entity_extraction.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(GRAPH_EXTRACTION_PROMPT)\r\n\r\n        summarize_descriptions = prompts_dir / \"summarize_descriptions.txt\"\r\n        if not summarize_descriptions.exists():\r\n            with summarize_descriptions.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(SUMMARIZE_PROMPT)\r\n\r\n        claim_extraction = prompts_dir / \"claim_extraction.txt\"\r\n        if not claim_extraction.exists():\r\n            with claim_extraction.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(CLAIM_EXTRACTION_PROMPT)\r\n\r\n        community_report = prompts_dir / \"community_report.txt\"\r\n        if not community_report.exists():\r\n            with community_report.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(COMMUNITY_REPORT_PROMPT)\r\n                \r\n    def set_settings(self):\r\n        env_path = os.path.join(self.persist_directory, \".env\")\r\n        if os.path.isfile(env_path) or os.path.islink(env_path):\r\n            os.unlink(env_path)\r\n        f = open(env_path, \"w\", encoding='utf-8')\r\n        if self.llm._llm_type == \"ollama-chat\":\r\n            f.write(\"GRAPHRAG_API_KEY=ollama\\n\")\r\n        else:\r\n            f.write(f\"GRAPHRAG_API_KEY={self.llm.openai_api_key.get_secret_value()}\\n\")\r\n        f.close()\r\n\r\n        with open(os.path.join(self.persist_directory, \"settings.yaml\"), \"r\", encoding='utf-8') as f:\r\n            configs = yaml.safe_load(f)\r\n        configs['embeddings']['llm']['model'] = self.embedding.model\r\n        configs['storage']['type'] = self.storage_type\r\n        if self.llm._llm_type == \"ollama-chat\":\r\n            configs['llm']['model'] = self.llm.model\r\n            configs['llm']['lang_llm_type'] = \"ollama\"\r\n            configs['llm']['api_base'] = f'{self.llm.base_url}/v1'\r\n            configs['embeddings']['llm']['lang_llm_type'] = \"ollama\"\r\n            configs['embeddings']['llm']['api_base'] = f'{self.llm.base_url}/api'\r\n        else:\r\n            configs['llm']['model'] = self.llm.model_name\r\n            if configs['llm'].get('api_base'):\r\n                del configs['llm']['api_base']\r\n            configs['llm']['lang_llm_type'] = \"openai\"\r\n            if configs['embeddings']['llm'].get('api_base'):\r\n                del configs['embeddings']['llm']['api_base']\r\n            configs['embeddings']['llm']['lang_llm_type'] = \"openai\"\r\n        with open(os.path.join(self.persist_directory, \"settings.yaml\"), \"w\", encoding='utf-8') as f:\r\n            yaml.dump(configs, f)","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"persist_directory":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"name":"persist_directory","value":"","display_name":"Persist Directory","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"MessageTextInput"},"storage_type":{"trace_as_metadata":true,"options":["memory","blob","file"],"combobox":false,"required":true,"placeholder":"","show":true,"name":"storage_type","value":"file","display_name":"Storage Type","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str","_input_type":"DropdownInput"}},"description":"A component that uses GraphRag to index data.","base_classes":["Message"],"display_name":"Microsoft GraphRAG Store","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"result_text","display_name":"Text","method":"save_data","value":"__UNDEFINED__","cache":true}],"field_order":["llm","embedding","persist_directory","storage_type","ingest_data"],"beta":false,"edited":true,"lf_version":"1.0.15","official":false},"id":"GraphRagStore-xQav2"},"id":"GraphRagStore-xQav2","position":{"x":0,"y":0},"type":"genericNode"}],"viewport":{"x":1,"y":1,"zoom":1}},"is_component":true}